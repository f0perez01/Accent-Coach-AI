# Quick Start Guide - Accent Coach AI (Microservices Architecture)

## üöÄ Running the Application

The application has been refactored into a clean microservices architecture. Here's how to run it:

### 1. Prerequisites

```bash
# Ensure you're in the project directory
cd c:\Users\f0per\f28\Accent-Coach-AI

# Activate virtual environment
venv\Scripts\activate

# Install dependencies (if not already installed)
pip install -r requirements.txt
```

### 2. Environment Configuration

Create a `.env` file in the project root with your API keys:

```env
# Groq API Key for LLM services
GROQ_API_KEY=your_groq_api_key_here

# Optional: Hugging Face token for ASR models
HF_TOKEN=your_huggingface_token_here
```

### 3. Running the Streamlit App

The main entry point is still `streamlit_app.py`, but now it uses the new architecture:

```bash
streamlit run streamlit_app.py
```

## üèóÔ∏è Architecture Overview

The application now follows **Domain-Driven Design** with clear **Bounded Contexts**:

```
accent_coach/
‚îú‚îÄ‚îÄ domain/                  # Business logic (Bounded Contexts)
‚îÇ   ‚îú‚îÄ‚îÄ audio/              # BC1: Audio Processing
‚îÇ   ‚îú‚îÄ‚îÄ transcription/      # BC2: Speech Recognition (ASR)
‚îÇ   ‚îú‚îÄ‚îÄ phonetic/           # BC3: Phonetic Analysis
‚îÇ   ‚îú‚îÄ‚îÄ pronunciation/      # BC4: Pronunciation Practice
‚îÇ   ‚îú‚îÄ‚îÄ conversation/       # BC5: Conversation Practice
‚îÇ   ‚îú‚îÄ‚îÄ writing/            # BC7: Writing Coach
‚îÇ   ‚îî‚îÄ‚îÄ language_query/     # BC8: Language Query
‚îú‚îÄ‚îÄ infrastructure/          # Technical capabilities
‚îÇ   ‚îú‚îÄ‚îÄ llm/                # BC6: LLM Orchestration
‚îÇ   ‚îú‚îÄ‚îÄ persistence/        # Repositories (in-memory/Firestore)
‚îÇ   ‚îî‚îÄ‚îÄ activity/           # Activity tracking
‚îî‚îÄ‚îÄ presentation/            # UI layer (Streamlit)
```

## üìù Usage Examples

### Example 1: Pronunciation Practice (BC4)

```python
from accent_coach.domain.pronunciation.service import PronunciationPracticeService
from accent_coach.domain.pronunciation.models import PracticeConfig
from accent_coach.domain.audio.service import AudioService
from accent_coach.domain.transcription.service import TranscriptionService
from accent_coach.domain.phonetic.service import PhoneticAnalysisService
from accent_coach.infrastructure.llm.groq_provider import GroqLLMService
import os

# Initialize services with dependency injection
audio_service = AudioService()
transcription_service = TranscriptionService()
phonetic_service = PhoneticAnalysisService()
llm_service = GroqLLMService(api_key=os.getenv("GROQ_API_KEY"))

# Create pronunciation practice service
pronunciation_service = PronunciationPracticeService(
    audio_service=audio_service,
    transcription_service=transcription_service,
    phonetic_service=phonetic_service,
    llm_service=llm_service
)

# Analyze a recording
config = PracticeConfig(use_llm_feedback=True)
result = pronunciation_service.analyze_recording(
    audio_bytes=audio_data,
    reference_text="hello world",
    user_id="user123",
    config=config
)

print(f"Phoneme Accuracy: {result.analysis.metrics.phoneme_accuracy}")
print(f"Word Accuracy: {result.analysis.metrics.word_accuracy}")
print(f"LLM Feedback: {result.llm_feedback}")
```

### Example 2: Writing Coach (BC7)

```python
from accent_coach.domain.writing.service import WritingService
from accent_coach.domain.writing.models import WritingConfig, QuestionCategory, QuestionDifficulty
from accent_coach.infrastructure.llm.groq_provider import GroqLLMService
import os

# Initialize services
llm_service = GroqLLMService(api_key=os.getenv("GROQ_API_KEY"))
writing_service = WritingService(llm_service=llm_service)

# Get a practice question
question = writing_service.get_question_by_category(
    category=QuestionCategory.BEHAVIORAL,
    difficulty=QuestionDifficulty.MEDIUM
)
print(f"Question: {question.text}")
print(f"XP Value: {question.get_xp_value()}")

# Evaluate user's answer
user_answer = "I worked on a challenging project last year where I had to learn React quickly."
config = WritingConfig()

evaluation = writing_service.evaluate_writing(
    text=user_answer,
    config=config
)

print(f"CEFR Level: {evaluation.metrics.cefr_level}")
print(f"Variety Score: {evaluation.metrics.variety_score}/10")
print(f"Corrected: {evaluation.corrected}")
print(f"Improvements: {evaluation.improvements}")

# Get warm teacher feedback
feedback = writing_service.generate_teacher_feedback(
    evaluation=evaluation,
    original_text=user_answer
)
print(f"Teacher Feedback: {feedback}")
```

### Example 3: Language Query (BC8)

```python
from accent_coach.domain.language_query.service import LanguageQueryService
from accent_coach.domain.language_query.models import QueryConfig
from accent_coach.infrastructure.llm.groq_provider import GroqLLMService
import os

# Initialize services
llm_service = GroqLLMService(api_key=os.getenv("GROQ_API_KEY"))
query_service = LanguageQueryService(llm_service=llm_service)

# Process a language query
result = query_service.process_query(
    user_query="Is 'touch base' commonly used in American English?",
    conversation_history=[],
    config=QueryConfig()
)

print(f"Category: {result.category.value}")
print(f"Response: {result.llm_response}")

# Follow-up query with context
conversation_history = [
    {
        "user_query": result.user_query,
        "llm_response": result.llm_response
    }
]

result2 = query_service.process_query(
    user_query="Can you give me more examples?",
    conversation_history=conversation_history
)
print(f"Follow-up Response: {result2.llm_response}")
```

### Example 4: Conversation Practice (BC5)

```python
from accent_coach.domain.conversation.service import ConversationService
from accent_coach.domain.conversation.models import ConversationConfig, ConversationMode
from accent_coach.infrastructure.llm.groq_provider import GroqLLMService
import os

# Initialize services
llm_service = GroqLLMService(api_key=os.getenv("GROQ_API_KEY"))
conversation_service = ConversationService(llm_service=llm_service)

# Create a new conversation session
config = ConversationConfig(
    mode=ConversationMode.PRACTICE,
    topic="Technology",
    proficiency_level="intermediate"
)

session = conversation_service.create_session(
    user_id="user123",
    config=config
)

# Get starter prompt
from accent_coach.domain.conversation.starters import ConversationStarters
starter = ConversationStarters.get_starter_by_topic("Technology")
print(f"Starter: {starter}")

# Process a conversation turn
turn_result = conversation_service.process_turn(
    session_id=session.session_id,
    user_transcript="I think artificial intelligence will change how we work.",
    user_id="user123"
)

print(f"Correction: {turn_result.correction}")
print(f"Follow-up: {turn_result.follow_up}")
```

## üß™ Running Tests

The application has comprehensive test coverage (79% overall, 100% for key services):

```bash
# Run all unit tests
python -m pytest tests/unit/ -v

# Run specific test file
python -m pytest tests/unit/test_writing_service.py -v

# Run with coverage report
python -m pytest tests/unit/ --cov=accent_coach --cov-report=html

# View coverage report
# Open htmlcov/index.html in browser
```

## üìä Test Statistics

| Sprint | Bounded Context | Tests | Coverage |
|--------|----------------|-------|----------|
| 1-2 | Audio, ASR, Activity | 20 | 65% |
| 3 | Phonetic Analysis | 13 | 93% |
| 4 | Conversation Practice | 16 | 94% |
| 5 | LLM Enhancements | 6 | 98% |
| 6 | Writing Coach | 18 | 97% |
| 7 | Language Query | 17 | 100% |
| 8 | Pronunciation Practice | 10 | 100% |
| **Total** | **8 Bounded Contexts** | **128** | **79%** |

## üîß Service Integration

All services use **Dependency Injection** for clean architecture:

### Service Dependencies

```
PronunciationService (BC4)
‚îú‚îÄ‚îÄ AudioService (BC1)
‚îú‚îÄ‚îÄ TranscriptionService (BC2)
‚îú‚îÄ‚îÄ PhoneticAnalysisService (BC3)
‚îî‚îÄ‚îÄ LLMService (BC6)

ConversationService (BC5)
‚îî‚îÄ‚îÄ LLMService (BC6)

WritingService (BC7)
‚îî‚îÄ‚îÄ LLMService (BC6)

LanguageQueryService (BC8)
‚îî‚îÄ‚îÄ LLMService (BC6)
```

### Repository Pattern

All services support optional repository injection for persistence:

```python
from accent_coach.infrastructure.persistence.in_memory_repositories import (
    InMemoryPronunciationRepository,
    InMemoryWritingRepository,
    InMemoryConversationRepository
)

# Use in-memory repositories (for testing or simple deployments)
pronunciation_repo = InMemoryPronunciationRepository()
writing_repo = InMemoryWritingRepository()
conversation_repo = InMemoryConversationRepository()

# Or use Firestore repositories (for production)
from accent_coach.infrastructure.persistence.firestore_adapter import FirestoreAdapter
# firestore_adapter = FirestoreAdapter(project_id="your-project")
```

## üéØ Key Features by Bounded Context

### BC1: Audio Processing
- Audio normalization
- TTS generation (normal/slow speed)
- Quality validation

### BC2: Transcription (ASR)
- Wav2Vec2 model support
- G2P (grapheme-to-phoneme) conversion
- Multi-language support

### BC3: Phonetic Analysis
- Phoneme-level comparison
- Accuracy metrics calculation
- Word-level drill suggestions

### BC4: Pronunciation Practice
- Full orchestration (Audio ‚Üí ASR ‚Üí Phonetic ‚Üí LLM)
- LLM-powered feedback
- Practice result persistence

### BC5: Conversation Practice
- Practice & Exam modes
- Multi-turn conversations
- Grammar correction + follow-up questions
- Topic-based starters

### BC6: LLM Orchestration
- Groq integration (Llama 3.1)
- Cost tracking
- Domain-specific prompts:
  - Pronunciation feedback
  - Conversation tutoring
  - Writing evaluation
  - Teacher feedback
  - Language query responses

### BC7: Writing Coach
- Job interview preparation
- CEFR level assessment
- Vocabulary expansion
- 37-question practice bank
- XP/gamification system

### BC8: Language Query
- Expression naturalness evaluation
- 7-category detection
- Conversation history support
- American English focus

## üö¶ Migration Status

| Component | Status | Notes |
|-----------|--------|-------|
| Audio Processing | ‚úÖ Complete | Fully tested |
| ASR/Transcription | ‚úÖ Complete | Fully tested |
| Phonetic Analysis | ‚úÖ Complete | 93% coverage |
| Pronunciation Practice | ‚úÖ Complete | Orchestration working |
| Conversation Practice | ‚úÖ Complete | 94% coverage |
| LLM Integration | ‚úÖ Complete | 98% coverage |
| Writing Coach | ‚úÖ Complete | 97% coverage |
| Language Query | ‚úÖ Complete | 100% coverage |
| Streamlit UI | ‚è≥ In Progress | Needs refactoring to use new services |

## üìö Additional Resources

- [SPRINT5_COMPLETED.md](SPRINT5_COMPLETED.md) - LLM Integration details
- [SPRINT6_COMPLETED.md](SPRINT6_COMPLETED.md) - Writing Coach implementation
- [SPRINT7_COMPLETED.md](SPRINT7_COMPLETED.md) - Language Query implementation
- [Architecture Documentation](docs/architecture.md) - Detailed architecture diagrams

## üêõ Troubleshooting

### Issue: Import Errors
**Solution**: Ensure you're in the project root and virtual environment is activated.

### Issue: LLM API Errors
**Solution**: Check that `GROQ_API_KEY` is set in `.env` file.

### Issue: Test Failures
**Solution**: Run `pip install -r requirements.txt` to ensure all dependencies are installed.

### Issue: Audio Processing Errors
**Solution**: Ensure audio files are in correct format (WAV, 16kHz sample rate recommended).

## üí° Best Practices

1. **Always use Dependency Injection**: Never create services inside other services.
2. **Use Configuration Objects**: Pass config objects instead of many parameters.
3. **Handle Errors Gracefully**: All services include error handling.
4. **Test with Mocks**: Unit tests should mock all dependencies.
5. **Follow Repository Pattern**: Use repositories for persistence, not direct DB access.

## üéâ Next Steps

1. Run the application: `streamlit run streamlit_app.py`
2. Explore the test suite: `python -m pytest tests/unit/ -v`
3. Read the sprint documentation for implementation details
4. Start using individual services in your own code!

---

**Questions?** Check the sprint documentation files or review the test files for usage examples.
