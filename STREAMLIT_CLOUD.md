# Streamlit Cloud Deployment Guide

## Problema Resuelto: OSError en Streamlit Cloud

### El Error

```
OSError: This app has encountered an error...
File "/mount/src/accent-coach-ai/app.py", line 214, in load_asr_model
```

**Causa**: El modelo `facebook/wav2vec2-large-960h` (~2GB) es demasiado grande para el tier gratuito de Streamlit Cloud, que tiene **limitaciones de espacio en disco**.

### ‚úÖ Soluci√≥n Implementada

He cambiado el modelo por defecto a **`facebook/wav2vec2-base-960h`** que es:
- ‚úÖ **M√°s peque√±o** (~360MB vs ~2GB)
- ‚úÖ **M√°s r√°pido** de descargar
- ‚úÖ **Compatible con Streamlit Cloud** gratuito
- ‚úÖ **Buena precisi√≥n** (95%+ accuracy en la mayor√≠a de casos)

## Cambios Realizados

### 1. Nuevos Modelos Disponibles

```python
MODEL_OPTIONS = {
    "Wav2Vec2 Base (Fast, Cloud-Friendly)": "facebook/wav2vec2-base-960h",  # DEFAULT
    "Wav2Vec2 Large (Better Accuracy, Needs More RAM)": "facebook/wav2vec2-large-960h",
    "Wav2Vec2 XLSR (Phonetic)": "mrrubino/wav2vec2-large-xlsr-53-l2-arctic-phoneme",
}
```

### 2. Modelo por Defecto

El modelo **Base** se usa por defecto, ideal para:
- Streamlit Cloud (tier gratuito)
- M√°quinas con poca RAM
- Testing r√°pido
- La mayor√≠a de casos de uso

## Configuraci√≥n en Streamlit Cloud

### Paso 1: Crear `secrets.toml`

En el dashboard de Streamlit Cloud:

1. Ve a **"Manage app"**
2. Selecciona **"Settings"**
3. Abre **"Secrets"**
4. A√±ade:

```toml
GROQ_API_KEY = "your-groq-api-key-here"
# HF_API_TOKEN = "your-hf-token" # Opcional
```

### Paso 2: Configurar requirements.txt

Aseg√∫rate de que `requirements.txt` tiene versiones espec√≠ficas para evitar conflictos:

```txt
torch>=2.0.0,<2.2.0
torchaudio
transformers>=4.30.0
streamlit>=1.28.0
```

### Paso 3: Recursos del Sistema

**Tier Gratuito de Streamlit Cloud**:
- CPU: 1 core
- RAM: 1GB
- Storage: Limitado (~5GB temporal)

**Recomendaciones**:
- ‚úÖ Usa `Wav2Vec2 Base` (default)
- ‚úÖ Audio < 10 segundos
- ‚úÖ Desactiva otros servicios pesados durante el uso

## Comparaci√≥n de Modelos

| Modelo | Tama√±o | RAM | Precisi√≥n | Cloud Gratuito |
|--------|--------|-----|-----------|----------------|
| **Base** | ~360MB | ~1GB | 95%+ | ‚úÖ S√ç |
| **Large** | ~2GB | ~4GB | 97%+ | ‚ùå NO |
| **XLSR** | ~1.2GB | ~3GB | 96%+ | ‚ö†Ô∏è Depende |

## Troubleshooting en Cloud

### Error: "Out of disk space"

**Soluci√≥n**:
1. Usa el modelo Base (ya configurado por defecto)
2. O actualiza a Streamlit Cloud Pro ($20/mes)

### Error: "CUDA out of memory"

**Soluci√≥n**:
- Streamlit Cloud no tiene GPU
- El c√≥digo autom√°ticamente usa CPU
- No requiere acci√≥n

### Procesamiento Lento

**Normal en tier gratuito**:
- Primera carga: 30-60 segundos (descarga modelo)
- An√°lisis: 5-15 segundos
- Cacheo funciona despu√©s de la primera ejecuci√≥n

**Para mejorar**:
- Reduce duraci√≥n del audio
- Usa el modelo Base

### Error: "ModuleNotFoundError"

**Soluci√≥n**:
```bash
# Verifica que requirements.txt est√° completo
# Streamlit Cloud instala autom√°ticamente
```

Si persiste, a√±ade al `requirements.txt`:
```txt
phonemizer
python-Levenshtein
```

## Monitoreo

### Ver Logs

En Streamlit Cloud:
1. Click **"Manage app"**
2. Click **"Logs"**
3. Busca errores en tiempo real

### M√©tricas de Uso

- CPU: Disponible en dashboard
- RAM: Muestra warnings si est√° alto
- Storage: No visible directamente

## Optimizaciones Adicionales

### 1. Cach√© Agresivo

```python
@st.cache_resource(ttl=3600)  # Cache por 1 hora
def load_asr_model(model_name: str, hf_token: Optional[str] = None):
    ...
```

### 2. L√≠mite de Duraci√≥n de Audio

```python
MAX_AUDIO_DURATION = 15  # segundos

if duration > MAX_AUDIO_DURATION:
    st.error(f"Audio too long. Max {MAX_AUDIO_DURATION}s")
```

### 3. Procesamiento por Lotes

Para m√∫ltiples usuarios simult√°neos, considera:
- API externa (Groq, OpenAI Whisper API)
- Queue system
- Rate limiting

## Alternativas a Streamlit Cloud

Si necesitas el modelo Large:

### 1. Streamlit Cloud Pro
- $20/mes
- 4 cores, 4GB RAM
- Puede manejar modelo Large

### 2. Otros Hosting
- **Railway**: $5/mes, m√°s recursos
- **Render**: Free tier con 512MB RAM
- **Hugging Face Spaces**: Free tier con 16GB RAM
- **Google Colab**: Gratis con GPU

### 3. Self-Hosted
```bash
# En tu servidor
streamlit run app.py --server.port 8501
```

## Testing Local vs Cloud

### Local (Desarrollo)
```bash
# Puedes usar cualquier modelo
streamlit run app.py
```

### Cloud (Producci√≥n)
- Usa modelo Base por defecto
- Prueba l√≠mites de recursos
- Monitorea logs

## Deployment Checklist

Antes de deploy:

- [ ] `requirements.txt` completo
- [ ] Secrets configurados (GROQ_API_KEY)
- [ ] Modelo Base como default
- [ ] Audio limits configurados
- [ ] Error handling robusto
- [ ] README actualizado
- [ ] `.gitignore` incluye secrets locales

## URL de Tu App

Una vez deployed:
```
https://share.streamlit.io/[username]/accent-coach-ai/main/app.py
```

O app_alternative.py:
```
https://share.streamlit.io/[username]/accent-coach-ai/main/app_alternative.py
```

## Pr√≥ximos Pasos

1. **Push cambios** a GitHub
2. **Refresh app** en Streamlit Cloud (autom√°tico)
3. **Verifica** que el modelo Base se carga correctamente
4. **Prueba** con audio de 5-10 segundos
5. **Monitorea logs** para errores

## Soporte

Si el error persiste:
1. Verifica logs en Streamlit Cloud
2. Confirma que usa modelo Base
3. Prueba con audio m√°s corto (<5s)
4. Considera upgrade a Pro tier

---

**¬°Listo!** Tu app ahora deber√≠a funcionar en Streamlit Cloud tier gratuito. üéâ
